{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenein- und Ausgabe\n",
    "\n",
    "Die Hauptanwendung von Python (oder jeder anderen Programmiersprache) in eurer späteren Arbeit wir die Verarbeitung und Analyse von Daten sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='slides/img/8_data_life_cycle.png' width='50%' />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu werdet ihr sowohl selbst erhobene Daten (Simulationen, Messungen) als auch bereits bestehende Daten verwenden. Das Teilen und verfügbar machen Daten ist ein zentraler Bestandteil der wissenschaftlichen Praxis. Deshalb solltet Ihr schon beim Prozessieren der eigenen Daten daran denken, diese vollständig mit [Metadaten](https://de.wikipedia.org/wiki/Metadaten) zu beschreiben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schlechtes Beispiel:**\n",
    "\n",
    "      0|    1|    2|    3|    4|    5|    6|    7|    8|    9|\n",
    "    ----------------------------------------------------------\n",
    "    1.2| 2.34|  4.6| 2.31|567.1|45.24| 4.63|1.855|  4.2|  1.5|\n",
    "\n",
    "\n",
    "**Gutes Beispiel:**\n",
    "\n",
    "    Incubator experiment No. 3456\n",
    "    Date: 13.03.2018\n",
    "    Contact: Martin Claus <mclaus@geomar.de>\n",
    "    Bacteria: Escherichia coli\n",
    "    Substrate: Agar plates\n",
    "    Cultivation: 10 days following Aaronson et al. (2017)\n",
    "    \n",
    "    temperature [°C]   |   0|    1|    2|    3|    4|    5|    6|    7|    8|    9|\n",
    "    -----------------------------------------------------------------------------\n",
    "    growth rate [1/day]| 1.2| 2.34|  4.6| 2.31|567.1|45.24| 4.63|1.855|  4.2|  1.5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Datenformat\n",
    "\n",
    "Das Datenformat bezeichnet die Art, wie die Daten strukturiert sind und wie sie bei ihrer Verarbeitung zu interpretieren sind. Generell kann man klassifizieren nach:\n",
    "\n",
    "-   Selbstbeschreibende Datenformate: Metadaten enthalten\n",
    "\n",
    "-   nicht-selbstbeschreibende Datenformate: Metadaten sind getrennt von Daten\n",
    "\n",
    "Weiter kann man klassifizieren nach der Art, wie die Datenkodiert sind\n",
    "\n",
    "-   Binäre Datenformate:\n",
    "    Daten werden in binärform gespeichert (wie sie im Speicher sind). Das Datenformat (i.e. Anzahl Bits, Datentyp, etc.)\n",
    "    muss bekannt sein und sollte in den Metadaten enthalten sein\n",
    "    \n",
    "-   Textbasierte Datenformate:\n",
    "    Die Informationen sind als Textzeichen codiert (ASCII, UTF-8 oder ähnliches). Die Codierung und die Struktur der\n",
    "    Daten muss bekannt sein.\n",
    "    \n",
    "Generell ist davon abzuraten, nicht-selbtsbeschreibende binäre Datenformate zu verwenden, da man diese nicht ohne weiteres weiter geben kann.\n",
    "\n",
    "Im Folgenden werden wir zwei weit verbreitete Datenformate betrachten:\n",
    "\n",
    "-   CSV (Comma Separated Values): Textbasiertes Datenformat für tabulare Daten\n",
    "-   NetCDF: selbstbeschreibendes binäres Datenformat für Multidimensionale Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Beispiel verwenden wir den [Hurrel North Atlantic Oscillation Index (station based)](https://climatedataguide.ucar.edu/climate-data/hurrell-north-atlantic-oscillation-nao-index-station-based). Der Inhalt der Textdatei hat folgende Struktur: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 data/nao_station_monthly.txt\n",
    "!echo ...\n",
    "!tail -n 5 data/nao_station_monthly.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Struktur kann beschrieben werden durch:\n",
    "\n",
    "-  2 Kopfzeilen\n",
    "-  13 Spalten (Jahr, Jan., Feb., ...)\n",
    "-  fehlende Werte sind durch '-999.' markiert\n",
    "\n",
    "Um die Daten in den Speicher zu laden verwenden wir die Funktion [numpy.genfromtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt). Falls wir keine fehlenden Werte haben, können wir auch alternativ [numpy.loadtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html#numpy.loadtxt) verwenden.\n",
    "\n",
    "**Aufgabe**: Laden die Daten der Datei 'data/nao_station_monthly.txt'. Maskiere dabei die fehlenden Werte. Dafür brauchst du folgende Parameter der Funktion np.genfromtxt:\n",
    "\n",
    "-   skipt_header\n",
    "-   missing_values\n",
    "-   usemask\n",
    "\n",
    "Speichere die Daten in einen Array. Versuche danach, die Daten so umzustrukturieren, dass du einen Zeitvektor (1D-array) und einen Datenvektor erhälst, der zeitlich fortlaufend ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, nao)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('nao')\n",
    "plt.title('station based monthly NAO index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NETCDF\n",
    "\n",
    "[NetCDF](https://www.unidata.ucar.edu/software/netcdf/docs/user_guide.html) ist ein Datenformat für arraybasierte multidimensionale binäre Daten, welches selbstbeschreibend ist. NetCDF ist auch eine Sammelung von Bibliotheken und Werkzeugen, um NetCDF Dateien zu öffnen oder mit Ihnen zu Arbeiten.\n",
    "\n",
    "### Struktur eine NetCDF Datensatzes\n",
    "Um sich den Inhalt oder die Struktur eine Datensatzes anzuschauen, verwendet man den Befehl [ncdump](https://www.unidata.ucar.edu/software/netcdf/docs/netcdf_utilities_guide.html#ncdump_guide) in der Linux Kommandozeile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncdump -h data/CRUTEM.4.6.0.0.anomalies.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von diesem Output kann man folgende Datenstruktur erkennen:\n",
    "\n",
    "Ein Datensatz besteht aus:\n",
    "\n",
    "-   Dimensionen\n",
    "-   Variablen\n",
    "-   globalen Attributen\n",
    "\n",
    "-  Dimensionen haben einen Namen und eine Länge. Um Dimensionen mit Koordinaten zu versehen, existieren Variablen mit dem gleichen Namen.\n",
    "-  Variablen haben\n",
    "   -   einen Datentyp\n",
    "   -   einen Namen\n",
    "   -   einen shape, definiert durch ein Tuple von Dimensionen\n",
    "   -   Attribute\n",
    "-  Attribute haben\n",
    "   -   einen Namen\n",
    "   -   einen Datentyp\n",
    "   -   einen Wert\n",
    "\n",
    "Beachte die Länge der Dimension `time`. Diese ist `UNLIMITED`. Das bedeuted, dass die Länge der variabel ist und man jederzeit zusätzliche Zeitscheiben anhängen kann. Dies ist praktisch beim Schreiben von Datensätzen. Beim lesen, insbesondere von großen Datensätzen, ist dies mit Geschwindigkeitseinbußen verbunden.\n",
    "\n",
    "Standardnamen und -werte für Attribute und Variablen sind für klimabezogene Datensätze in den [Climate and Forecast Metadata Conventions (CF conventions)](http://cfconventions.org/) festegelegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun öffnen wir diesen Datensatz mit Hilfe des [netCDF4](https://unidata.github.io/netcdf4-python/netCDF4/index.html) Pakets. Dies tun wir, indem wir ein Objekt der Klasse [netCDF4.Dataset](https://unidata.github.io/netcdf4-python/netCDF4/index.html#netCDF4.Dataset) erstellen. Wir können uns die Struktur des Datensatzes anschauen, indem wir das Datensatz Objekt printen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = nc.Dataset('data/CRUTEM.4.6.0.0.anomalies.nc')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Daten und Metadaten des Datensatzes sind als Attribute des Datensatzobjektes verfügbar. Die wichtigsten Attribute sind\n",
    "\n",
    "-   dimensions:\n",
    "\n",
    "    Dictionary, welches die Dimensionsnamen auf Ojekte der Klasse [Dimension](https://unidata.github.io/netcdf4-python/netCDF4/index.html#netCDF4.Dimension) abbildet.\n",
    "    \n",
    "-   variables:\n",
    "\n",
    "    Dictionary, welches die Variablenname auf Objekte der Klasse [Variable](https://unidata.github.io/netcdf4-python/netCDF4/index.html#netCDF4.Variable) abbildet. Diese werden verwendet, um Daten zu lesen oder zu schreiben und um\n",
    "    auf die Attribute der Variable zuzugreifen.\n",
    "    \n",
    "Die globalen Attribute sind als Attribute des Datensatzobjekts verfügbar (z.B. `ds.reference`)\n",
    "\n",
    "**Aufgabe:**\n",
    "-   Untersuche den Inhalt der Attribute `dimensions` und `variables`. Wie Lang sind die Dimensionen `longitude` und `time`? Welche Einheit und Datentyp hat die Variable `temperature_anomaly` und auf welchen Dimensionen ist sie definiert? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesen von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Daten aus einer Variable in einem netCDF Datensatz in den Speicher zu lesen, wird lediglich das Variablenobjekt indiziert.\n",
    "\n",
    "**Aufgabe:**\n",
    "-   Lese den letzten Zeitschritt der Variable `temperature_anomaly` in den Speicher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_anom = ...\n",
    "\n",
    "plt.pcolormesh(\n",
    "    ds.variables['longitude'][:],\n",
    "    ds.variables['latitude'][:],\n",
    "    t_anom\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe**: Berechne die global gemittelte Temperatur Anomalie. Da die Daten in spärischen Koordinate vorliegen, müssen die einzelnen Datenpunkte mit dem Cosinus der Breite im Bogenmaß gewichtet werden:\n",
    "\n",
    "$$ t_{global} = \\frac{1}{N M}\\sum_{j=1}^M\\sum_{i=1}^{N} t_{anom}(j, i) \\cos(\\theta(j))$$\n",
    "\n",
    "Versuche dabei, die Broadcasting Funktionalität und die Mittelwertfunktion von Numpy zu verwenden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = ds.variables['latitude'][:]\n",
    "t_anom = ds.variables['temperature_anomaly'][:]\n",
    "\n",
    "t_global = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nc.num2date(ds.variables['time'][:], ds.variables['time'].units), t_G);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben von netCDF Datensätzen\n",
    "\n",
    "So leicht NetCDF Datensätze gelesen werden können, so umständlich sind sie zu schreiben. Folgende Schritte sind notwendig, um einen Datensatz zu schreiben:\n",
    "\n",
    "1.   Datensatzobjekt erstellen und globale Attribute setzen:\n",
    "\n",
    "```python\n",
    "ds = nc.Dataset('test.nc', mode='w')\n",
    "ds.contact = 'Martin Claus <mclaus@geomar.de>'\n",
    "ds.description = 'Zonally averaged surface temperature from NCEP Reanalysis'\n",
    "ds.data_source = 'https://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html'\n",
    "ds.creation_date = '16-06-2019'\n",
    "```\n",
    "\n",
    "2. Dimensionen erstellen:\n",
    "\n",
    "```python\n",
    "ds.createDimension('latitude', 20)\n",
    "ds.createDimension('time', None)   # unlimited dimension\n",
    "```\n",
    "\n",
    "3. Variablen erstellen:\n",
    "\n",
    "```python\n",
    "lon = ds.createVariable('latitude', 'f8', dimensions=('latitude',))\n",
    "time = ds.createVariable('time', 'f8', dimensions=('time',))\n",
    "t = ds.createVariable('temperature', 'f8', dimensions=('time', 'longitude')\n",
    "```\n",
    "\n",
    "4. Variablendaten schreiben und Attribute anlegen\n",
    "\n",
    "```python\n",
    "lon[:] = np.linspace(-80., 80., 20.)\n",
    "lon.units = \"degrees_north\"\n",
    "lon.long_name = \"Latitude\"\n",
    "\n",
    "time.units = 'days since 2012-01-01 00:00'\n",
    "time.calendar = 'gregorian'\n",
    "time.long_name = 'Time'\n",
    "\n",
    "t.units = 'degC'\n",
    "t.long_name = 'zonally averaged temperature'\n",
    "\n",
    "# write timestamp and data\n",
    "time[0] = 0.\n",
    "t[0, :] = ...\n",
    "```\n",
    "\n",
    "5. Datensatz schließen (erst jetzt wird auf die Festplatte geschrieben)\n",
    "\n",
    "```python\n",
    "ds.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Schreibe die oben ausgerechnete Temperaturzeitreihe inkl. aller relevanten Metadaten in einen NetCDF Datensatz. Verwende dabei möglichst viele Informationen aus dem Quelldatensatz.\n",
    "\n",
    "Hinweis: Um einen existierenden Datensatz zu überschreiben, muss man das Argument `clobber=True` beim erstellen des Datensatzes verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Andere Datenformate\n",
    "\n",
    "\n",
    "Format   |     Bibliothek\n",
    "---------|---------------\n",
    "JSON     |   [json](https://docs.python.org/3/library/json.html)\n",
    "XML      |   [xml.etree.ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html)\n",
    "xls      |   in csv umwandeln oder [pandas](https://pandas.pydata.org/)\n",
    "mat      |   [scipy.io.loadmat](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html#scipy.io.loadmat)\n",
    "shp      |   [pyshp](https://pypi.org/project/pyshp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
